---
title: Теория индексов
subtitle: Что нужно знать, чтобы писать быстрые запросы в SQL
id: index-theory
---

## Введение

SQL является мощным декларативным языком и скрывает от программиста большинство технических деталей. Простые на первый взгляд запросы на поверку оказываются медленными, что становится неприятным сюрпризом как для программистов, так и для пользователей.

В попытках повысить производительность, начинающие программисты зачастую действуют методом перебора, а это не самый быстрый способ обучения. Для того чтобы писать эффективные запросы, требуется понимание принципов работы СУБД.

В этой статье я расскажу о производительности запросов `SELECT`. Упор буду делать не на детали конкретных реализаций, а на фундамент,
который лежит в основе любого SQL-сервера.

## Волшебная сила порядка

Для начала давайте разберёмся, что такое быстрый поиск, и как он работает. Предположим, у нас есть телефонный справочник, где записаны все жители города с адресами и телефонами. Чтобы сделать его, мы разослали по городу переписчиков с анкетами и составили один большой список.

Предположим, мы хотим найти адрес Александра Сергеевича Пушкина. Нам придётся читать все записи подряд, пока мы не встретим нужное нам имя. Если справочник содержит *N* жителей, в худшем случае нам придётся прочитать *N* записей.

Для больших *N* это может быть очень долго. Поэтому в настоящих справочниках жители упорядочены по фамилии и имени. Поиск нужного жителя идёт методом *половинного деления* или *двоичного поиска*. Мы открываем справочник где-то посередине и ищем нужную фамилию. Обычно на первой попавшейся странице её нет, и мы двигаемся дальше.
Так как фамилии упорядочены, мы можем сразу сообразить, где находится нужный нам человек: в первой половине книги, или во-второй. Мы открываем эту половину книги тоже где-то посередине и повторяем поиск.

На каждом шаге мы сокращаем размер списка вдвое до тех пор, пока он не станет равным 1. Если в справочнике *N* жителей, то нужного нам человека мы найдём в худшем случае за *log₂ N* попыток.

Много это или мало? Если в городе один миллион жителей, то, если список неупорядочен, мы найдём человека за миллион попыток. А если упорядочен&nbsp;&mdash; всего за 20. И чем больше *N*, тем больше эта разница.

Я подготовил таблицу, где можно увидеть, насколько медленно растёт *log₂ N* по сравнению с *N*.

Скобки &lceil; и &rceil; означают &laquo;округаление вверх&raquo;. Мы должны округлить результат вверх, потому что логарифм по основанию два&nbsp;&mdash; число обычно нецелое, скажем, для 513 он равен 9,002815016. В худшем случае нам придётся делать одно лишнее сравнение, потому что 0,002815016 сравнений быть не может.

Третья колонка таблицы показывает отношение *N* и *&lceil;log₂ N&rceil;*. Для тысячи записей оно равно 100, то есть двоичный поиск работает в сто раз быстрее, чем перебор. Для миллиона чисел двоичный поиск работает в пятьдесят тысяч раз быстрее, а для миллиарда&nbsp;&mdash; в тридцать миллионов раз быстрее!

|     N     | &lceil;log₂ N&rceil; |  N/&lceil;log₂ N&rceil; |
|       1000|                    10|                      100|
|      10000|                    14|                      714|
|     100000|                    17|             5&thinsp;882|
|    1000000|                    20|            50&thinsp;000|
|   10000000|                    24|           416&thinsp;667|
|  100000000|                    27|  3&thinsp;703&thinsp;704|
| 1000000000|                    30| 33&thinsp;333&thinsp;333|

Такова волшебная сила упорядоченного набора данных.

## Способы упорядочивания

Предположим, что мы хотим найти телефон человека, зная его адрес. У нас есть телефонный справочник, где записи упорядочены по фамилии. Сколько времени нам потребуется, чтобы завершить поиск? Оказывается, что в худшем случае речь снова идёт о *N* попытках. То, что справочник упорядочен по фамилии, никак не помогает искать человека по адресу.

Чтобы решить такую задачу, нам нужен второй справочник, с другим способом сортировки.

Конечно, справочники с разной сортировкой встречаются нечасто. Чтобы двигаться дальше, нам нужна новая метафора, которая поможет разобраться с двумя или тремя способами упорядочивания. И поможет нам метафора библиотеки.

В библиотеке способ размещения книг неважен, потому что вместо книг библиотекари упорядочивают карточки. Если мы хотим искать книги по названию, то для каждой книги мы заводим карточку, где записываем *название книги* и её *место*, то есть номер шкафа и полки.

Мы размещаем карточки в алфавитном порядке. Чтобы найти книгу, мы сначала ищем карточку, используя метод *половинного деления*, как и в примере с телефонным справочником. Узнав место хранения книги, идём и забираем её.

Этот способ сложнее, потому что он включает в себя и поиск карточки, и поиск книги. С другой стороны, он позволяет использовать столько картотек, сколько нам надо, и искать книги не только по названию, но и по фамилии автора, и по ISBN, и по людым другим полям.

Другое название картотеки это *указатель*, поскольку карточки *указывают*, где лежит книга. По английски указатель называется *index*. Метафора библиотеки помогает понять, что такое *индексы* в СУБД. Поле, по которому упорядочены карточки, в реляционной теории называется *ключом*.

## Диапазоны и составные ключи

Иногда нам нужна не конкретная запись а набор записей, попадающий под условия поиска. Продолжим метафору с библиотекой. В библиотеке хранят не только книги, но и периодические издания, например, ежемесячные журналы.

Как найти все журналы, выпущенные весной 2004-го года? Если у нас нет картотеки по дате выхода, то найти их можно будет только методом перебора, то есть медленно. А если у нас есть картотека?

Оказывается, двоичный поиск поможет нам и в этом случае. Мы запишем на карточках год и месяц выхода журнала, и расположим их в порядке возрастания года. Если годы совпадают, то в порядке возрастания месяца.

С помощью двоичного поиска мы сначала найдём начало диапазона: карточку 2004-03 за март 2004-го года. Затем мы найдём конец диапазона: карточку 2004-05. Поскольку карточки упорядочены по возрастанию даты, результатом поиска будут первая карточка, последняя карточка и всё, что окажется между ними.

Алгоритм поиска будет немного отличаться от простого варианта. Очевидно, в марте 2004-го года вышел не один журнал, и в картотеке наверняка окажется несколько карточек с датой 2004-03. В начале диапазона нам надо искать самую первую, а в конце&nbsp;&mdash; самую последнюю. Этот более сложный алгоритм, потребует приблизительно столько же сравнений&nbsp;&mdash; *log₂ N*.

Не смотря на высокую скорость поиска начала и конца, проблема с производительностью здесь всё же возможна. Если в диапазон попадёт слишком много журналов, например, тысяча, нам придётся тысячу раз извлекать их с книжных полок, чтобы отдать читателю.

Чуть позже мы обсудим, как можно справиться с этой проблемой, а пока обратим внимание на важную особенность нашей картотеки. Мы упорядочили карточки не по одному полю, а по двум&nbsp;&mdash; году и месяцу. В реляционной теории такой ключ называется *составным*.
Если мы захотим найти все журналы за 2004 и 2005 годы, нам не придётся создавать новую картотеку с ключом &laquo;год&raquo;., поскольку индекс по году у нас уже присутствует.

К сожалению, если мы захотим найти все жунралы, вышедшие в марте, индекс по году и месяцу нам не поможет, потому что мартовские журналы за разные годы будут находиться в разных местах картотеки. Человек мог бы в этой ситуации сократить время поиска, опираясь на понимание того, что такое &laquo;год&raquo;, но для сервера баз данных это просто число, поэтому он вернётся к методу перебора.

## Детали реализации&nbsp;&mdash; данные

Всякая аналогия ложна. Чтобы избежать неверных выводов из нашей библиотечной метафоры, поговорим о том, как устроены *полки* и *карточки* в компьютерах. Исторически базы данных появлись чуть позже дисковых накопителей, которые сейчас называют *жёсткими дисками* или *винчестерами*. Какие особенности важны для винчестеров? Во-первых, мы не можем прочитить или записать один байт. У винчестера есть минимальный объём информации, который может быть записан или прочитан за один раз, он называется *сектор* и содержит 512 байт. Если нам надо изменить один байт, мы должны прочитать сектор в оперативную память целиком, там изменить этот байт, и записать весь сектор обратно.

Во-вторых, на жёстком диске большое время занимает первоначальное позиционирование магнитной головки. Гораздо быстрее прочитать несколько секторов подряд на одной дорожке, чем в разных местах диска. По этим соображениям, и по некоторым другим, операционная система разрешает читать данные с диска не единичными секторами, а целыми *кластерами*. Кластеры обычно состоят из 4-х, 8-ми, 16-ти секторов. Вожможны разные варианты, но мы не будем углубляться в детали. Нам важно понять, почему размер блока при работе с жётским диском составляет что-то вроде 4 или 8 килобайт.

Сервер баз данных хранит данные в так называемых *страницах*, размер которых кратен размеру кластера. Сервер кэширует страницы в оперативной памяти целиком. Страницы, которые используются часто, постоянно находятся в памяти, а остальные загружаются по мере надобности.

Точный размер страниц зависит от СУБД, обычно это от 4 до 64 килобайт. Страницы используются как для хранения записей, так и для
хранения индексов, и в каждом случае есть своя специфика.

Страницы с данными похожи на книжные полки: каждая запись&nbsp;&mdash; это книга. Страница, как и полка, может быть *полупустой*. Если пользователь удаляет запись, место на странице освобождается, но сервер не будет вставлять туда новые записи, потому что это медленно. При заполнении страницы, сервер создаст новую пустую страницу и разместит следующую запись там.

Чтобы избавиться от пустых страниц в середине, нужно выполнить *сжатие* базы (shrink database). Эта операция не входит в стандарт SQL и не все серверы её поддерживают.

Размер одной записи не может превышать размер страницы. Прочитав это, вы, наверное, удивитесь, потому что в базе данных можно хранить и большие двоичные объекты (BLOB'ы, от Binary Large Objects), и большие текстовые поля. На самом деле такие поля хранятся отдельно от остальной записи на страницах специального типа, но детали сейчас неважны. Важно, что записи всегда помещаются на странице целиком, и что записей на странице может быть несколько, иногда несколько десятков и даже сотен.

## Детали реализации&nbsp;&mdash; индексы

Страницы с индексами устроены гораздо интереснее. Для их хранения используется структура данных, которая называется B-дерево (читается *би дерево*). Подробно она описана в третьем томе *Искусства программирования*, посвящённом сортировке и поиску.

Не погружаясь в детали, разберёмся, что это за структура и для чего она нужна. Как мы помним, для быстрого поиска элементы индекса должны быть упорядочены. Простейшая структура данных, с помощью которой возможен быстрый поиск, это обыкновенный массив.

Время поиска в отсортированном массиве пропорционально *log N*. Математики говорят, что временная сложность двоичного поиска равна *Θ(log N)*, то есть *тета-большое от логарифма*. Вместо греческой буквы Θ часто используют латинскую букву O и пишут *O(log N)*, *о-большое от логарифма*. Это не совсем корректно, но считается приемлимым для прикладной литературы.

Проблемы массива начинаются тогда, когда мы добавляем или удаляем элемент. Чтобы поиск продолжал работать, нам надо сохранять порядок элементов. Мы не можем просто добавлять новые элементы в конец, мы должны вставлять их в правильные места. Найти правильное место нетрудно&nbsp;&mdash; *O(log N)*, но *вставка* и *удаление* требуют сдвигать элементы массива к началу или к концу и требуют *O(N)* операций. Это уже довольно медленно.

Чтобы справиться с этой проблемой, вместо массива применяют *двоичное дерево*, в котором и поиск, и вставка, и удаление выполняются в среднем за время *O(log N)*. К сожалению у двоичного дерева бывает вырожденный случай, который возникает, если добавлять в дерево упорядоченные элементы. В каждом узле вырожденного дерева есть только правые (или только левые) поддеревья. Скорость поиска, вставки и удаления в таком дереве равна *O(N)*.

Мы избежим вырожденного случая, если будем *балансировать* дерево после удалений и вставок. В сбалансированном дереве любое левое и правое поддерево не слишком сильно отличаются друг от друга по высоте. Есть несколько алгоритмов балансировки, и каждый из них приводит к тому, что худшее время поиска, вставки и удаления в сбалансированном дереве составляет *O(log N)*.

Это уже очень здорово, но нам пора вспомнить, что наша база может быть очень большой. Двоичное дерево может просто не поместиться в оперативную память. Как раз в этогм случае нам и нужно B-дерево, которое можно считать адаптацией сбалансированного двоичного дерева для постраничного хранения.


## Составные ключи

Люди столкнулись с задачей поиска задолго до того, как появились компьютеры. Одним из самых 

План статьи
1.	Введение
a.	Низкая производительность приложений, работающих с БД — это проблема. Чтобы решить проблему, надо узнать причину низкой производительности.
b.	Причина низкой производительности — непонимание принципов работы СУБД.
c.	Самое узкое место — производительность запросов SELECT.
2.	Задача.
a.	Таблицы, записи, поля. Пример таблицы.
b.	Выборка, поиск.
c.	Представление записей.
3.	Структуры данных и Алгоритмы.
a.	Представление записей в виде структур/классов.
b.	Бинарные деревья, узлы деревьев. Проблемы.
c.	Извлечение i-той записи.
d.	Индексация.
e.	Сбалансированные деревья.
f.	Хранение индексов на диске. B-деревья.
4.	Производительность простых выборок.
a.	Поиск записи по ключу.
b.	Выборка записей по диапазону ключей.
c.	Количество записей.
d.	Сортировка.

Структуры данных и алгоритмы
Чтобы упростить изложение, давайте предположим, что все записи нашей таблицы помещаются в оперативную память. Каждая запись хранится в структуре (в терминах языка C), или в классе с открытыми полями (в терминах C++, Java, C#):
public class HttpLogRecord
{
  public int id;
  public DateTime time;
  public string ip;
  public string method;
  public string uri;
  public int size;
  public int status;
}
Большинство программистов более-менее представляют себе, что в качестве базовой структуры для хранения таблицы используется бинарное дерево. Каждый узел такого дерева содержит одну запись и ссылки на левый и правый дочерние узлы:
public class BinaryTreeNode
{
  public HttpLogRecord record;
  public BinaryTreeNode leftChild;
  public BinaryTreeNode rightChild;
}
Бинарное дерево позволяет эффективно осуществлять все основные операции с таблицей:
Операция	Среднее время выполнения
Поиск записи по ключу	O(logn)
Получение i-той записи	O(n)
Определение минимума и максимума	O(logn)
Вставка	O(logn)
Удаление	O(logn)
Сортировка	O(m), где m — размер выборки
Однако тривиальная реализация бинарных деревьев обладает несколькими недостатками:
•	Очень дорогой оказывается операция получения записи по её порядковому номеру. Между тем, эта операция очень важна в веб-разработке (например, позволяет получить записи с порядковыми номерами от 3000 до 3019).
•	Бинарное дерево поддерживает только один порядок сортировки, определяемый первичным ключом. Если нам нужна выборка, упорядоченная по дате/времени, придётся осуществлять сортировку повторно, а быстродействие такой операции гораздо ниже.
•	Наконец, бинарное дерево может оказаться вырожденным. Такое происходит, если в таблицу вставляются уже упорядоченные данные. При тривиальной реализации дерево превратится в однонаправленный список (все левые дочерние узлы пусты, дерево растёт только по крайней правой ветке; или наоборот).
Скорость операций поиска, вставки, удаления для вырожденного дерева составляет O(n), что очень медленно для больших таблиц.
Давайте посмотрим, как можно обойти эти недостатки.
Извлечение i-той записи
Для того, чтобы ускорить поиск записи по её порядковому номеру, в каждом узле бинарного дерева необходимо хранить количество узлов в левом поддереве, а также ссылку на родительский узел.
public class BinaryTreeNode
{
  public HttpLogRecord record;
  public int leftSubTreeSize;
  public BinaryTreeNode parent;
  public BinaryTreeNode leftChild;
  public BinaryTreeNode rightChild;
}
При вставке/удалении узла, мы должны пробежаться до корня (с помощью ссылки parent), и, поднимаясь из левого поддерева, увеличивать/уменьшать поле leftSubTreeSize. Эффективность такой операции составляет O(logn). Обратите внимание, что первой записью в бинарном дереве в данном случае является самый левый лист, а последней — самый правый.
Чтобы найти запись по порядковому номеру, необходимо немного изменить алгоритм бинарного поиска. Порядковый номер корневой записи точно равен leftSubTreeSize, так что мы сразу можем определить: в левом или правом поддереве находится нужная запись, и затем действовать рекурсивно. Производительность поиска i-той записи в данном случае составляет O(logn).
Обращаю ваше внимание, что с помощью этой техники мы можем не только быстро извлекать записи по порядковому номеру, но и определять порядковый номер записей за время O(logn).
Индексация
Хранение записей в виде бинарного дерева предполагает, что нам доступен только один порядок сортировки. Решить эту проблему позволяет дополнительный уровень косвенности.
Вместо того, чтобы хранить записи в бинарном дереве, мы размещаем их в большом массиве. Каждый узел бинарного дерева содержит не саму запись, а её порядковый номер в этом массиве:
public class BinaryTreeNode
{
  public int recordIndex;
  public int leftSubTreeSize;
  public BinaryTreeNode parent;
  public BinaryTreeNode leftChild;
  public BinaryTreeNode rightChild;
}
Благодаря такой косвенной адресации, мы можем одновременно использовать несколько бинарных деревьев с разным порядком сортировки.
Поскольку бинарное дерево содержит порядковые номера записей, то есть индексы, его для краткости так и называют — индекс, а сам процесс построения индекса — индексацией.
Несколько интересных следствий:
•	Мы в любой момент можем создать новый индекс или восстановить повреждённый, поэтому СУБД позволяют переиндексировать таблицы, если цел массив записей. Создание индекса — ресурсоёмкая операция, фактически, это сортировка массива, и её эффективность равна O(n×logn).
•	Не смотря на то, что дополнительный уровень косвенности увеличивает накладные расходы, их эффективность составляет O(1), то есть не зависит от количества записей. Чтобы добиться такой производительности, после удаления записей массив не уплотняется, и в нём остаются пустые места. СУБД позволяют уплотнять таблицы, но поскольку производительность этой операции составляет O(n), уплотнение следует производить нечасто, и только во время минимальной нагрузки на SQL-сервер.
•	Размер узла в бинарном дереве небольшой, по сравнению с размером записи. Даже для нашей 10-тимиллионой таблицы, индекс можно держать в оперативной памяти полностью, что кардинально увеличит производительность. Именно поэтому СУБД так требовательны к оперативной памяти.
•	Один из индексов таблицы (как правило, самый используемый) объявляется первичным. С точки зрения реализации это ничего не означает, поэтому в некоторых СУБД объявление первичного индекса не обязательно.
Сбалансированные деревья
Если в бинарное дерево вставляются упорядоченные записи, дерево вырождается в список, и эффективность операций поиска ухудшается до O(n).
Для решения этой проблемы, после вставки и удаления узлов бинарное дерево перестраивается так, чтобы избежать вырождения. За подробностями я отсылаю читателей в Google (искать по ключевым словам «сбалансированные деревья», «AVL деревья», «красно-чёрные деревья»). Упрощённо можно считать, что записи в сбалансированном дереве распределены более-менее равномерно, и эффективность поиска всегда составляет O(logn).
Балансировка дерева требует накладных расходов, производительность которых равна O(logn).
Эффективность операций со сбалансированным деревом и быстрым поиском i-той записи приведена ниже:
Операция	Худшее время выполнения
Поиск записи по ключу	O(logn)
Получение i-той записи	O(logn)
Определение минимума и максимума	O(logn)
Вставка	O(logn)
Удаление	O(logn)
Сортировка	O(m), где m — размер выборки
B-деревья (сильноветвящиеся деревья)
Наконец, мы обсудим вопрос хранения индекса на диске. Для решения этой задачи в СУБД используются B-деревья (би-деревья), которые в русскоязычной литературе называются также сильноветвящимися.
B-деревья используют те же принципы, что и сбалансированные, но в отличие от последних, они могут храниться на диске отдельными блоками. Подробнее с B-деревьями вы можете ознакомиться в разделе 6.2.4 многотомника Д. Кнута («Искусство программирования», том III), либо через Google.
С точки зрения принципов работы СУБД, B-деревья не привносят ничего нового, однако заинтересованному читателю будет полезно разобраться с этой структурой данных.
Производительность простых выборок
Поиск записи по ключу
Рассмотрим извлечение одной записи из таблицы HttpLog по её идентификатору:
SELECT * FROM HttpLog WHERE id = @id
Если в таблице предусмотрен индекс по полю id, эффективность поиска составит O(logn), в противном случае — O(n).
Поиск записей по двум ключам:
SELECT * FROM HttpLog WHERE status = 404 and ip = @ip
Составной индекс по полями [status, ip] или [ip, status] позволит найти нужную запись за время O(logn).
Рекомендация: если вы ищете в таблице записи с конкретными значениями полей, создавайте индекс по этим полям. Порядок следования полей в индексе значения не имеет.
Выборка записей по диапазону ключей
Извлечём из лога HTTP-сервера все записи со статусом 4xx (ошибка):
SELECT * FROM HttpLog WHERE status >= 400 AND status <= 499
В данном случае, SQL-сервер, пользуясь индексом по полю status, может определить диапазон узлов в бинарном дереве, удовлетворяющих условию. Если индекс построен по возрастанию поля status, то при обходе дерева слева направо SQL-сервер извлечёт все требуемые записи из таблицы. Если же индекс построен по убыванию, SQL-сервер сможет обойти дерево справа налево.
Поиск первой и последней записи требует времени O(logn). Однако реальная эффективность запроса зависит от размера выборки, и составляет O(m), где m — количество записей, удовлетворяющих условию.
К сожалению, в нашем конкретном случае количество записей может оказаться очень большим (несколько сотен тысяч). Для того, чтобы справиться с этой проблемой, мы могли бы показывать записи постранично (в данном запросе используется синтаксис MySQL):
SELECT * FROM HttpLog WHERE status >= 400 AND status <= 499 LIMIT @startIndex, @pageSize
SQL-сервер, может найти запись с порядковым номером @startIndex за время O(logn). Размер выборки составит @pageSize (как правило, не больше ста). Таким образом, скорость выполнения запроса может вырасти в 1000 раз.
Рекомендация: при выборке по диапазону ключей, создавайте индекс по соответствующему полю. Следите за объёмом выборки, в сложных случаях принимайте меры для того, чтобы ограничить выборку.
Количество записей
Попробуем узнать, сколько всего запросов вызвали ошибку 4xx:
SELECT COUNT(*) FROM HttpLog WHERE status >= 400 AND status <= 499
SQL-сервер может определить порядковые номера первой записи и последней записи диапазона за время O(logn). Вычтя первое число из второго, он получит количество записей в диапазоне.
Рекомендации: при наличии индекса, выполнение операции COUNT становится очень быстрым.
Сортировка
Предположим, мы хотим получить список всех запросов за день, отсортированный по возрастанию даты/времени запроса:
SELECT * FROM HttpLog WHERE DATE(time) = ‘2007-01-03’ ORDER BY time ASC
При наличии индекса время выполнения запроса составит O(logn + m), не зависимо от возрастания/убывания поля time в индексе. Границы диапазона будут найдены за время O(logn), и затем SQL-сервер, обойдя дерево слева направо (или справа налево), выберет все записи внутри диапазона. Обратите внимание, что эти записи будут упорядочены.
При отсутствии индекса, SQL-серверу потребуется O(n) операций, для того, чтобы выбрать m записей, и затем ещё O(m×logm) операций, чтобы их упорядочить. Суммарное время выполнения запроса составит O(n + m×logm). Очевидно, что если мы используем упорядоченные выборки, нам необходимо создать соответствующие индексы (не важно, по возрастанию или убыванию).
Давайте рассмотрим похожий пример: выберем все записи со статусом 404 и упорядочим их по возрастанию даты/времени:
SELECT * FROM HttpLog WHERE status = 404 ORDER BY time ASC
Индекс по полям [time, status] нас в данном случае не спасёт, поскольку сервер будет проверять все значения time, которых может оказаться много. А вот индекс [status, time] позволит сразу найти границы диапазона, где status = 404, внутри которого записи будут упорядочены по полю time. Порядок возрастания/убывания в данном случае не важен.
Точное совпадение порядка ключей в индексе и клаузе ORDER BY требуется и в таких запросах:
SELECT * FROM HttpLog ORDER BY ip ASC, status DESC
И, хотя, теоретически, порядок в данном случае может оказаться некритичным, лучше предоставить серверу возможность выбирать записи подряд, то есть создать индекс [ip ASC, status DESC]. Похожий запрос:
SELECT * FROM HttpLog WHERE size < 100 ORDER BY ip ASC, status DESC
требует индекса [ip ASC, status DESC, size], а не [size, ip ASC, status DESC], как могло бы показаться на первый взгляд. При этом порядок возрастания/убывания для поля size не важен.
Рекомендации: обратите внимание на все запросы, содержащие клаузу ORDER BY. Создайте индексы для всех используемых порядков сортировки. Обратите внимание на запросы, где выборка производится по одним полям, а сортировка по другим — здесь потребуются сложные индексы.

## Задача

Статья носит практический характер, поэтому я буду приводить конкретные примеры, а для этого мне понадобится простая таблица,
структура которой знакома многим веб-разработчикам. Речь идёт о логе HTTP-сервера:

```sql
CREATE TABLE HttpLog
(
  id INT NOT NULL                        -- уникальный идентификатор записи
  time DATETIME NOT NULL,                -- дата/время запроса
  ip CHAR(15) NOT NULL,                  -- IP-адрес клиента
  method CHAR(8) DEFAULT ‘GET’ NOT NULL, -- метод: GET, POST, PUT и т.д.
  uri VARCHAR(2048) NOT NULL,            -- адрес страницы в виде /path/filename.ext
  size INT NOT NULL,                     -- ответ сервера (размер в байтах)
  status INT NOT NULL                    -- статус: 200, 302, 404, 501 и т.д.
)
```

В этой таблице хранится каждое обращение к HTTP-серверу. Я взял несколько полей из реальных логов, которые помогут нам строить запросы.

> В комментариях к этой статье мне заметили, что IP-адрес можно хранить не в виде строки, а в виде четырёх двоичных байтов. Это приведёт к экономии дискового пространства,
> и к увеличению скорости работы. Я назову эту рекомендацию спорной. Код в учебных статьях принято упрощать, но я бы не стал упаковывать IP-адреса и в
> рабочем коде. Во-первых потому, что код станет сложным. Во-вторых потому, что с упакованными данными трудно работать вручную. В-третьих потому, что усложнение
> программы не окупится. Даже на очень большом логе выигрыш составит несколько мегабайт, что при текущей цене на диски составит **несколько центов в год**.
>
> Возможное ускорение запросов вряд ли удастся обнаружить статистически, потому что сравнение четырех или четырнадцати байт&nbsp;&mdash; только часть работы,
> которую выполняет SQL сервер. Очень небольшая часть.
>
> Поэтому в этой статье мы не станем заниматься микрооптимизацией.

Содержимое таблицы, то есть лог посещений сервера, может быть таким:

|id |time                |ip            |method |uri                   |size  |status
|---|--------------------|--------------|-------|----------------------|------|------
|1  |2007-01-03 15:59:34 |192.168.10.68 |GET    |/images/name.gif      |1254  |404
|2  |2007-01-03 15:59:34 |192.168.10.68 |GET    |/images/combo.gif     |743   |200
|3  |2007-01-03 15:59:34 |192.168.10.68 |GET    |/images/harddrive.gif |947   |200
|4  |2007-01-03 16:00:33 |192.168.10.70 |POST   |/index.php	           |200   |6723
|5  |2007-01-03 16:01:52 |192.168.10.70 |GET    |/scripts/scripts.js   |11743 |200

Если наш сайт посещает десять тысяч человек в день, и каждый просматривает в среднем десять страниц, то за один квартал у нас наберётся приблизительно десять миллионов записей.
Подобный размер таблиц встречается нечасто, но именно на таких объёмах лучше всего рассматривать вопросы производительности.

Помимо количества записей на скорость выполнения запросов влияет также размер выборки. Одно дело, когда из большой таблицы нам нужны тридцать строк, и совсем другое, когда их три миллиона.
Однако, даже с определением объёма выборки могут возникнуть проблемы:

```sql
SELECT SUM(size) FROM HttpLog WHERE MONTH(time) = 1 AND YEAR(time) = 2007
```

Здесь СУБД просуммирует приблизительно треть нашей таблицы, но вернёт всего одно число. Для определённости мы будем считать, что объём выборки соответствует количеству обработанных записей,
то есть в данном случае приблизительно равен трём миллионам.

Под поиском мы будем понимать такую выборку, которая возвращает или одну запись или ни одной. Обычно на уровне SQL-запросов поиск не считается отдельной операцией,
и является частным случаем выборки. Однако с точки зрения реализации, поиск&nbsp;&mdash; это отдельная, и очень важная операция.

