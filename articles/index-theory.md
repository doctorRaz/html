---
title: Теория индексов
subtitle: Что нужно знать, чтобы писать быстрые запросы в SQL
id: index-theory
---

## Введение

SQL является мощным декларативным языком и скрывает от программиста большинство технических деталей. Простые на первый взгляд запросы на поверку оказываются медленными, что становится неприятным сюрпризом как для программистов, так и для пользователей.

В попытках повысить производительность, начинающие программисты зачастую действуют методом перебора, а это не самый быстрый способ обучения. Для того чтобы писать эффективные запросы, требуется понимание принципов работы СУБД.

В этой статье я расскажу о производительности запросов `SELECT`. Упор буду делать не на детали конкретных реализаций, а на фундамент.
В то же время постараюсь иллюстрировать общие положения реальными примерами.

## Волшебная сила порядка

Для начала разберёмся, что такое быстрый поиск, и как он работает. Предположим, у нас есть телефонный справочник, где записаны все жители города с адресами и телефонами. Если мы просто запишем всех жителей, они будут расположены в справочнике безо всякого порядка.

Если мы хотим найти адрес Александра Сергеевича Пушкина, нам придётся читать все записи подряд, пока мы не встретим нужное нам имя. Если справочник содержит *N* жителей, в худшем случае нам придётся прочитать *N* записей.

Для больших *N* поиск займёт много времени, поэтому в настоящих справочниках жители упорядочены по фамилии и имени. Поиск нужного жителя идёт методом *половинного деления* или *двоичного поиска*. Мы открываем справочник где-то посередине и смотрим на первую и последнюю фамилии разворота. Предположим, последняя фамилия Лермонтов, это значит, что Пушкин окажется во второй половине справочника, потому что жители в списке расположены в алфавитном порядке.

Таким образом мы сразу сокращаем список приблизительно в два раза. Повторим поиск, пока не найдём нужный разворот. На каждом шаге список будет сокращаться вдвое. Если в справочнике *N* жителей, то нужного нам человека мы найдём в худшем случае за *log₂ N* попыток.

Много это или мало? Если в городе один миллион жителей, то, если список неупорядочен, худший случай составит миллион попыток. А если упорядочен&nbsp;&mdash; всего двадцать. И чем больше *N*, тем больше эта разница.

Я подготовил таблицу, где можно увидеть, насколько медленно растёт *log₂ N* по сравнению с *N*.

|     N     | &rceil;log₂ N&lceil; | &lfloor;N/log₂ N&rfloor; |
|----------:|---------------------:|-------------------------:|
|       1000|                    10|                       100|
|      10000|                    14|                       714|
|     100000|                    17|              5&thinsp;882|
|    1000000|                    20|             50&thinsp;000|
|   10000000|                    24|            416&thinsp;667|
|  100000000|                    27|   3&thinsp;703&thinsp;704|
| 1000000000|                    30|  33&thinsp;333&thinsp;333|

Скобки &rceil; и &lceil; означают округление вверх, а &lfloor; и &rfloor;&nbsp;&mdash; вниз.

Третья колонка показывает, насколько двоичный поиск быстрее перебора. Для тысячи записей в сто раз,, для миллиона&nbsp;&mdash; в пятьдесят тысяч раз, а для миллиарда&nbsp;&mdash; в тридцать миллионов раз!

Такова волшебная сила упорядоченного набора данных.

## Способы упорядочивания

Предположим, что мы хотим найти телефон человека, зная его адрес. У нас есть телефонный справочник, где записи упорядочены по фамилии. Сколько времени нам потребуется, чтобы завершить поиск? Оказывается, речь снова идёт об *N* попытках. То, что справочник упорядочен по фамилии, никак не помогает искать человека по адресу.

Чтобы решить такую задачу, нам нужен второй справочник, с другим способом сортировки.

Конечно, справочники с разной сортировкой встречаются нечасто. Чтобы двигаться дальше, нам нужна новая метафора, которая поможет разобраться с двумя или тремя способами упорядочивания. И поможет нам метафора библиотеки.

В библиотеке способ размещения книг неважен, потому что вместо книг библиотекари упорядочивают карточки. Если мы хотим искать книги по названию, то для каждой книги мы заводим карточку, где записываем *название книги* и её *место*, то есть номер шкафа и полки.

Мы размещаем карточки в алфавитном порядке. Чтобы найти книгу, мы сначала ищем карточку, используя метод *половинного деления*, как и в примере с телефонным справочником. Узнав место хранения книги, идём и забираем её.

Этот способ сложнее, потому что он включает в себя и поиск карточки, и поиск книги. С другой стороны, он позволяет использовать столько картотек, сколько нам надо, и искать книги не только по названию, но и по фамилии автора, и по ISBN, и по людым другим полям.

Другое название картотеки это *указатель*, поскольку карточки *указывают*, где лежит книга. По английски указатель называется *index*. Метафора библиотеки помогает понять, что такое *индексы* в СУБД.

## Диапазоны и составные ключи

Иногда нам нужна не конкретная запись а набор записей,попадающий под условия поиска. Продолжим метафору с библиотекой. В библиотеке хранят не только книги, но и периодические издания, например, ежемесячные журналы.

Как найти все журналы, выпущенные весной 2004-го года? Если у нас нет картотеки по дате выхода, то найти их можно будет только методом перебора, то есть медленно. А если у нас есть картотека?

Оказывается, двоичный поиск поможет нам и в этом случае. Мы запишем на карточках год и месяц выхода журнала, и расположим их в порядке возрастания года. Если годы совпадают, то в порядке возрастания месяца.

С помощью двоичного поиска мы сначала найдём начало диапазона: карточку 2004-03 за март 2004-го года. Затем найдём конец диапазона: карточку 2004-05. Поскольку карточки упорядочены по возрастанию даты, результатом поиска будут первая карточка, последняя карточка и всё, что окажется между ними.

Алгоритм поиска будет немного отличаться от простого варианта. Очевидно, в марте 2004-го года вышел не один журнал, и в картотеке наверняка окажется несколько карточек с датой 2004-03. В начале диапазона нам надо искать самую первую, а в конце&nbsp;&mdash; самую последнюю. Этот более сложный алгоритм, но он требует приблизительно столько же сравнений&nbsp;&mdash; *log₂ N*.

Поле, по которому составлен индекс (упорядочены карточки) в реляционной теории называется *ключом*. Часто применяют *составной ключ* из несколькоих полей, как в примере с годом и месяцем. Порядок полей в составном ключе критически важен.

Сейчас объясню, почему.

Если мы захотим найти все журналы за 2004 и 2005 годы, нам не придётся создавать новую картотеку с ключом &laquo;год&raquo;., поскольку индекс по году у нас уже присутствует&nbsp;&mdash; нам достаточно просто не учитывать месяц.

Но если мы захотим найти все жунралы, вышедшие в марте, индекс по году и месяцу нам не поможет, потому что мартовские журналы за разные годы будут находиться в разных местах картотеки. Человек мог бы в этой ситуации сократить время поиска, опираясь на понимание того, что такое &laquo;год&raquo;, но для сервера баз данных это просто число, поэтому он вернётся к перебору.

Другая проблема с производительностью возникает, если мы выбираем слишком большой диапазон. Найти начало и конец диапазона недолго, но если в него попадёт слишком много журналов, например, тысяча, нам придётся тысячу раз извлекать их с книжных полок, чтобы отдать читателю.

Чуть позже мы обсудим, как можно справиться с этой проблемой.

## Детали реализации&nbsp;&mdash; данные

Всякая аналогия ложна. Чтобы избежать неверных выводов из нашей библиотечной метафоры, поговорим о том, как устроены *полки* и *карточки* в компьютерах. Исторически базы данных появлись чуть позже дисковых накопителей, которые сейчас называют *жёсткими дисками* или *винчестерами*. Какие особенности важны для винчестеров? Во-первых, мы не можем прочитить или записать один байт. У винчестера есть минимальный объём информации, который может быть записан или прочитан за один раз, он называется *сектор* и содержит 512 байт. Если нам надо изменить один байт, мы должны прочитать сектор в оперативную память целиком, там изменить этот байт, и записать весь сектор обратно.

Во-вторых, на жёстком диске большое время занимает первоначальное позиционирование магнитной головки. Гораздо быстрее прочитать несколько секторов подряд на одной дорожке, чем в разных местах диска. По этим соображениям, и по некоторым другим, операционные системы разрешают читать данные с диска не единичными секторами, а целыми *кластерами*. Кластеры обычно состоят из 4-х, 8-ми, 16-ти секторов. Возможны разные варианты, и мы не будем углубляться в детали. Нам важно понять, почему размер блока при работе с жёстким диском составляет несколько килобайт.

Сервер баз данных хранит данные в так называемых *страницах*, размер которых кратен размеру кластера. Сервер кэширует страницы в оперативной памяти целиком. Страницы, которые используются часто, постоянно находятся в памяти, а остальные загружаются по мере надобности.

Точный размер страниц зависит от СУБД, обычно это от 4 до 64 килобайт. Страницы используются как для хранения записей, так и для
хранения индексов, и в каждом случае есть своя специфика.

Страницы с данными похожи на книжные полки: каждая запись&nbsp;&mdash; это книга. Страница, как и полка, может быть *полупустой*. Если пользователь удаляет запись, место на странице освобождается, но сервер не будет вставлять туда новые записи, потому что это медленно. При заполнении страницы, сервер создаст новую пустую страницу и разместит следующую запись там.

Чтобы избавиться от пустых страниц в середине, нужно выполнить *сжатие* базы (shrink database). Эта операция не входит в стандарт SQL и не все серверы её поддерживают.

Размер одной записи не может превышать размер страницы. Прочитав это, вы, наверное, удивитесь, потому что в базе данных можно хранить и большие двоичные объекты (BLOB'ы, от Binary Large Objects), и большие текстовые поля. На самом деле такие поля хранятся отдельно от остальной записи на страницах специального типа, но детали сейчас неважны. Важно, что записи всегда помещаются на странице целиком, и что записей на странице может быть несколько, иногда даже несколько десятков или сотен.

## Детали реализации&nbsp;&mdash; индексы

Страницы с индексами устроены гораздо интереснее. Для их хранения используется структура данных, которая называется B-дерево (читается *би дерево*). Подробно она описана в третьем томе *Искусства программирования*, посвящённом сортировке и поиску.

Не погружаясь в детали, разберёмся, что это за структура и для чего она нужна. Как мы помним, для быстрого поиска элементы индекса должны быть упорядочены. Простейшая структура данных, с помощью которой возможен быстрый поиск, это обыкновенный массив.

Время поиска в отсортированном массиве пропорционально *log N*. Математики говорят, что временная сложность двоичного поиска равна *Θ(log N)*, то есть *тета-большое от логарифма эн*. Вместо греческой буквы Θ часто используют латинскую букву O и пишут *O(log N)*, *о-большое от логарифма эн*. Это не совсем корректно, но считается приемлимым для прикладной литературы.

Проблемы массива начинаются тогда, когда мы добавляем или удаляем элемент. Чтобы поиск продолжал работать, нам надо сохранять порядок элементов&nbsp;&mdash; мы не можем просто добавлять новые элементы в конец, мы должны вставлять их в правильные места. Найти правильное место недолго&nbsp;&mdash; *O(log N)*, но *вставка* и *удаление* потребуют сдвигать элементы массива к началу или к концу. Временная сложность сдвига составляет *O(N)* операций. Это очень медленно.

Чтобы ускорить вставку и удаление, вместо массива применяют *двоичное дерево*, в котором и поиск, и вставка, и удаление выполняются за *O(log N)*. К сожалению у двоичного дерева бывает вырожденный случай, который возникает, если добавлять в дерево упорядоченные элементы. В каждом узле вырожденного дерева есть только правые (или только левые) поддеревья. Скорость поиска, вставки и удаления в таком дереве снова равна *O(N)*.

Мы избежим вырожденного случая, если будем *балансировать* дерево после удалений и вставок. В сбалансированном дереве узлы распределены более-менее равномерно. Есть несколько алгоритмов балансировки, и каждый из них приводит к тому, что худшее время поиска, вставки и удаления составляет *O(log N)*.

Это уже очень здорово. Однако, у нас остаётся проблема с размером базы. Если дерево не помещается в оперативную память, нужно хранить его на диске. Быстрее всего работать с диском постранично, и нам остаётся придумать, как разбить сбалансированное двоичное дерево на страницы.

К счастью, эту задачу уже решили за нас, придумав B-дерево. Мы не будем останавливаться на этой структуре подробно, но отметим несколько важных моментов:

1. У таблицы в базе данных может быть несколько индексов. Для каждого идекса будет создано своё B-дерево.
1. В узлах B-дерева хранятся копии ключевых полей. Это нужно для быстрого поиска: все данные для сравнения должны быть под рукой.
1. В узлах B-дерева помимо ключевых полей хранятся адреса записей на диске в виде пары чисел *номер страницы данных*, *номер записи на странице*.
1. Поиск единичного ключа, вставка ключа и удаление ключа требуют *O(log N)* времени.
1. Каждый новый индекс увеличивает время вставок и удалений, поэтому чем меньше индексов, тем быстрее.
1. Каждое новое поле в индексе увеличивает размер ключа и всё B-дерево, поэтому чем меньше полей, тем быстрее.

Как видим, некоторые правила противоречат друг другу. С одной стороны, чем больше индексов, тем быстрее выполняются запросы и&nbsp;&mdash; в то же время&nbsp;&mdash; медленнее выполняются вставки. Ниже мы на конкретных примерах и разберёмся, как строить индексы правильно.

## Типичные задачи

Вооружившись библиотечной метафорой и знанием деталей, решим несколько поисковых задач.

### Поиск книги по названию и автору

Предположим, у нас есть картотека по названиям книг и ищем мы &laquo;Книгу о вкусной и здоровой&raquo;. Я проверил на Озоне, там есть несколько таких книг разных авторов, в частности, Леси Кравецкой, Николая Могильного и Екатерины Капрановой.

Если наша картотека упорядочена только по названию книги (по одному ключевому слову), сложно ли будет найти книгу Капрановой? Оказывается, нет. Сначала мы ограничим поле поиска названием и получим несколько карточек, идущих подряд. Даже в очень большой библиотеке их окажется несколько десятков, не больше.

Нужную книгу можно найти, проверив все карточки, и это будет быстро. Быстро потому, что разных книг с одним и тем же названием не очень много, часто вообще одна. Специалисты по базам данных скажут, что у поля `Название` высокая *селективность*, близкая к 100%.

Чтобы вычислить *селективность* поля надо разделить количество его уникальных значений на общее количество записей, и выразить результат в процентах. Селективность уникального поля равна 100%, а селективность поля `Пол` для тысячи записей равна 2/1000&nbsp;&times; 100%, то есть 0,2%.

## Составные ключи

Люди столкнулись с задачей поиска задолго до того, как появились компьютеры. Одним из самых 

План статьи
1.	Введение
a.	Низкая производительность приложений, работающих с БД — это проблема. Чтобы решить проблему, надо узнать причину низкой производительности.
b.	Причина низкой производительности — непонимание принципов работы СУБД.
c.	Самое узкое место — производительность запросов SELECT.
2.	Задача.
a.	Таблицы, записи, поля. Пример таблицы.
b.	Выборка, поиск.
c.	Представление записей.
3.	Структуры данных и Алгоритмы.
a.	Представление записей в виде структур/классов.
b.	Бинарные деревья, узлы деревьев. Проблемы.
c.	Извлечение i-той записи.
d.	Индексация.
e.	Сбалансированные деревья.
f.	Хранение индексов на диске. B-деревья.
4.	Производительность простых выборок.
a.	Поиск записи по ключу.
b.	Выборка записей по диапазону ключей.
c.	Количество записей.
d.	Сортировка.

Структуры данных и алгоритмы
Чтобы упростить изложение, давайте предположим, что все записи нашей таблицы помещаются в оперативную память. Каждая запись хранится в структуре (в терминах языка C), или в классе с открытыми полями (в терминах C++, Java, C#):
public class HttpLogRecord
{
  public int id;
  public DateTime time;
  public string ip;
  public string method;
  public string uri;
  public int size;
  public int status;
}
Большинство программистов более-менее представляют себе, что в качестве базовой структуры для хранения таблицы используется бинарное дерево. Каждый узел такого дерева содержит одну запись и ссылки на левый и правый дочерние узлы:
public class BinaryTreeNode
{
  public HttpLogRecord record;
  public BinaryTreeNode leftChild;
  public BinaryTreeNode rightChild;
}
Бинарное дерево позволяет эффективно осуществлять все основные операции с таблицей:
Операция	Среднее время выполнения
Поиск записи по ключу	O(logn)
Получение i-той записи	O(n)
Определение минимума и максимума	O(logn)
Вставка	O(logn)
Удаление	O(logn)
Сортировка	O(m), где m — размер выборки
Однако тривиальная реализация бинарных деревьев обладает несколькими недостатками:
•	Очень дорогой оказывается операция получения записи по её порядковому номеру. Между тем, эта операция очень важна в веб-разработке (например, позволяет получить записи с порядковыми номерами от 3000 до 3019).
•	Бинарное дерево поддерживает только один порядок сортировки, определяемый первичным ключом. Если нам нужна выборка, упорядоченная по дате/времени, придётся осуществлять сортировку повторно, а быстродействие такой операции гораздо ниже.
•	Наконец, бинарное дерево может оказаться вырожденным. Такое происходит, если в таблицу вставляются уже упорядоченные данные. При тривиальной реализации дерево превратится в однонаправленный список (все левые дочерние узлы пусты, дерево растёт только по крайней правой ветке; или наоборот).
Скорость операций поиска, вставки, удаления для вырожденного дерева составляет O(n), что очень медленно для больших таблиц.
Давайте посмотрим, как можно обойти эти недостатки.
Извлечение i-той записи
Для того, чтобы ускорить поиск записи по её порядковому номеру, в каждом узле бинарного дерева необходимо хранить количество узлов в левом поддереве, а также ссылку на родительский узел.
public class BinaryTreeNode
{
  public HttpLogRecord record;
  public int leftSubTreeSize;
  public BinaryTreeNode parent;
  public BinaryTreeNode leftChild;
  public BinaryTreeNode rightChild;
}
При вставке/удалении узла, мы должны пробежаться до корня (с помощью ссылки parent), и, поднимаясь из левого поддерева, увеличивать/уменьшать поле leftSubTreeSize. Эффективность такой операции составляет O(logn). Обратите внимание, что первой записью в бинарном дереве в данном случае является самый левый лист, а последней — самый правый.
Чтобы найти запись по порядковому номеру, необходимо немного изменить алгоритм бинарного поиска. Порядковый номер корневой записи точно равен leftSubTreeSize, так что мы сразу можем определить: в левом или правом поддереве находится нужная запись, и затем действовать рекурсивно. Производительность поиска i-той записи в данном случае составляет O(logn).
Обращаю ваше внимание, что с помощью этой техники мы можем не только быстро извлекать записи по порядковому номеру, но и определять порядковый номер записей за время O(logn).
Индексация
Хранение записей в виде бинарного дерева предполагает, что нам доступен только один порядок сортировки. Решить эту проблему позволяет дополнительный уровень косвенности.
Вместо того, чтобы хранить записи в бинарном дереве, мы размещаем их в большом массиве. Каждый узел бинарного дерева содержит не саму запись, а её порядковый номер в этом массиве:
public class BinaryTreeNode
{
  public int recordIndex;
  public int leftSubTreeSize;
  public BinaryTreeNode parent;
  public BinaryTreeNode leftChild;
  public BinaryTreeNode rightChild;
}
Благодаря такой косвенной адресации, мы можем одновременно использовать несколько бинарных деревьев с разным порядком сортировки.
Поскольку бинарное дерево содержит порядковые номера записей, то есть индексы, его для краткости так и называют — индекс, а сам процесс построения индекса — индексацией.
Несколько интересных следствий:
•	Мы в любой момент можем создать новый индекс или восстановить повреждённый, поэтому СУБД позволяют переиндексировать таблицы, если цел массив записей. Создание индекса — ресурсоёмкая операция, фактически, это сортировка массива, и её эффективность равна O(n×logn).
•	Не смотря на то, что дополнительный уровень косвенности увеличивает накладные расходы, их эффективность составляет O(1), то есть не зависит от количества записей. Чтобы добиться такой производительности, после удаления записей массив не уплотняется, и в нём остаются пустые места. СУБД позволяют уплотнять таблицы, но поскольку производительность этой операции составляет O(n), уплотнение следует производить нечасто, и только во время минимальной нагрузки на SQL-сервер.
•	Размер узла в бинарном дереве небольшой, по сравнению с размером записи. Даже для нашей 10-тимиллионой таблицы, индекс можно держать в оперативной памяти полностью, что кардинально увеличит производительность. Именно поэтому СУБД так требовательны к оперативной памяти.
•	Один из индексов таблицы (как правило, самый используемый) объявляется первичным. С точки зрения реализации это ничего не означает, поэтому в некоторых СУБД объявление первичного индекса не обязательно.
Сбалансированные деревья
Если в бинарное дерево вставляются упорядоченные записи, дерево вырождается в список, и эффективность операций поиска ухудшается до O(n).
Для решения этой проблемы, после вставки и удаления узлов бинарное дерево перестраивается так, чтобы избежать вырождения. За подробностями я отсылаю читателей в Google (искать по ключевым словам «сбалансированные деревья», «AVL деревья», «красно-чёрные деревья»). Упрощённо можно считать, что записи в сбалансированном дереве распределены более-менее равномерно, и эффективность поиска всегда составляет O(logn).
Балансировка дерева требует накладных расходов, производительность которых равна O(logn).
Эффективность операций со сбалансированным деревом и быстрым поиском i-той записи приведена ниже:
Операция	Худшее время выполнения
Поиск записи по ключу	O(logn)
Получение i-той записи	O(logn)
Определение минимума и максимума	O(logn)
Вставка	O(logn)
Удаление	O(logn)
Сортировка	O(m), где m — размер выборки
B-деревья (сильноветвящиеся деревья)
Наконец, мы обсудим вопрос хранения индекса на диске. Для решения этой задачи в СУБД используются B-деревья (би-деревья), которые в русскоязычной литературе называются также сильноветвящимися.
B-деревья используют те же принципы, что и сбалансированные, но в отличие от последних, они могут храниться на диске отдельными блоками. Подробнее с B-деревьями вы можете ознакомиться в разделе 6.2.4 многотомника Д. Кнута («Искусство программирования», том III), либо через Google.
С точки зрения принципов работы СУБД, B-деревья не привносят ничего нового, однако заинтересованному читателю будет полезно разобраться с этой структурой данных.
Производительность простых выборок
Поиск записи по ключу
Рассмотрим извлечение одной записи из таблицы HttpLog по её идентификатору:
SELECT * FROM HttpLog WHERE id = @id
Если в таблице предусмотрен индекс по полю id, эффективность поиска составит O(logn), в противном случае — O(n).
Поиск записей по двум ключам:
SELECT * FROM HttpLog WHERE status = 404 and ip = @ip
Составной индекс по полями [status, ip] или [ip, status] позволит найти нужную запись за время O(logn).
Рекомендация: если вы ищете в таблице записи с конкретными значениями полей, создавайте индекс по этим полям. Порядок следования полей в индексе значения не имеет.
Выборка записей по диапазону ключей
Извлечём из лога HTTP-сервера все записи со статусом 4xx (ошибка):
SELECT * FROM HttpLog WHERE status >= 400 AND status <= 499
В данном случае, SQL-сервер, пользуясь индексом по полю status, может определить диапазон узлов в бинарном дереве, удовлетворяющих условию. Если индекс построен по возрастанию поля status, то при обходе дерева слева направо SQL-сервер извлечёт все требуемые записи из таблицы. Если же индекс построен по убыванию, SQL-сервер сможет обойти дерево справа налево.
Поиск первой и последней записи требует времени O(logn). Однако реальная эффективность запроса зависит от размера выборки, и составляет O(m), где m — количество записей, удовлетворяющих условию.
К сожалению, в нашем конкретном случае количество записей может оказаться очень большим (несколько сотен тысяч). Для того, чтобы справиться с этой проблемой, мы могли бы показывать записи постранично (в данном запросе используется синтаксис MySQL):
SELECT * FROM HttpLog WHERE status >= 400 AND status <= 499 LIMIT @startIndex, @pageSize
SQL-сервер, может найти запись с порядковым номером @startIndex за время O(logn). Размер выборки составит @pageSize (как правило, не больше ста). Таким образом, скорость выполнения запроса может вырасти в 1000 раз.
Рекомендация: при выборке по диапазону ключей, создавайте индекс по соответствующему полю. Следите за объёмом выборки, в сложных случаях принимайте меры для того, чтобы ограничить выборку.
Количество записей
Попробуем узнать, сколько всего запросов вызвали ошибку 4xx:
SELECT COUNT(*) FROM HttpLog WHERE status >= 400 AND status <= 499
SQL-сервер может определить порядковые номера первой записи и последней записи диапазона за время O(logn). Вычтя первое число из второго, он получит количество записей в диапазоне.
Рекомендации: при наличии индекса, выполнение операции COUNT становится очень быстрым.
Сортировка
Предположим, мы хотим получить список всех запросов за день, отсортированный по возрастанию даты/времени запроса:
SELECT * FROM HttpLog WHERE DATE(time) = ‘2007-01-03’ ORDER BY time ASC
При наличии индекса время выполнения запроса составит O(logn + m), не зависимо от возрастания/убывания поля time в индексе. Границы диапазона будут найдены за время O(logn), и затем SQL-сервер, обойдя дерево слева направо (или справа налево), выберет все записи внутри диапазона. Обратите внимание, что эти записи будут упорядочены.
При отсутствии индекса, SQL-серверу потребуется O(n) операций, для того, чтобы выбрать m записей, и затем ещё O(m×logm) операций, чтобы их упорядочить. Суммарное время выполнения запроса составит O(n + m×logm). Очевидно, что если мы используем упорядоченные выборки, нам необходимо создать соответствующие индексы (не важно, по возрастанию или убыванию).
Давайте рассмотрим похожий пример: выберем все записи со статусом 404 и упорядочим их по возрастанию даты/времени:
SELECT * FROM HttpLog WHERE status = 404 ORDER BY time ASC
Индекс по полям [time, status] нас в данном случае не спасёт, поскольку сервер будет проверять все значения time, которых может оказаться много. А вот индекс [status, time] позволит сразу найти границы диапазона, где status = 404, внутри которого записи будут упорядочены по полю time. Порядок возрастания/убывания в данном случае не важен.
Точное совпадение порядка ключей в индексе и клаузе ORDER BY требуется и в таких запросах:
SELECT * FROM HttpLog ORDER BY ip ASC, status DESC
И, хотя, теоретически, порядок в данном случае может оказаться некритичным, лучше предоставить серверу возможность выбирать записи подряд, то есть создать индекс [ip ASC, status DESC]. Похожий запрос:
SELECT * FROM HttpLog WHERE size < 100 ORDER BY ip ASC, status DESC
требует индекса [ip ASC, status DESC, size], а не [size, ip ASC, status DESC], как могло бы показаться на первый взгляд. При этом порядок возрастания/убывания для поля size не важен.
Рекомендации: обратите внимание на все запросы, содержащие клаузу ORDER BY. Создайте индексы для всех используемых порядков сортировки. Обратите внимание на запросы, где выборка производится по одним полям, а сортировка по другим — здесь потребуются сложные индексы.

## Задача

Статья носит практический характер, поэтому я буду приводить конкретные примеры, а для этого мне понадобится простая таблица,
структура которой знакома многим веб-разработчикам. Речь идёт о логе HTTP-сервера:

```sql
CREATE TABLE HttpLog
(
  id INT NOT NULL                        -- уникальный идентификатор записи
  time DATETIME NOT NULL,                -- дата/время запроса
  ip CHAR(15) NOT NULL,                  -- IP-адрес клиента
  method CHAR(8) DEFAULT ‘GET’ NOT NULL, -- метод: GET, POST, PUT и т.д.
  uri VARCHAR(2048) NOT NULL,            -- адрес страницы в виде /path/filename.ext
  size INT NOT NULL,                     -- ответ сервера (размер в байтах)
  status INT NOT NULL                    -- статус: 200, 302, 404, 501 и т.д.
)
```

В этой таблице хранится каждое обращение к HTTP-серверу. Я взял несколько полей из реальных логов, которые помогут нам строить запросы.

> В комментариях к этой статье мне заметили, что IP-адрес можно хранить не в виде строки, а в виде четырёх двоичных байтов. Это приведёт к экономии дискового пространства,
> и к увеличению скорости работы. Я назову эту рекомендацию спорной. Код в учебных статьях принято упрощать, но я бы не стал упаковывать IP-адреса и в
> рабочем коде. Во-первых потому, что код станет сложным. Во-вторых потому, что с упакованными данными трудно работать вручную. В-третьих потому, что усложнение
> программы не окупится. Даже на очень большом логе выигрыш составит несколько мегабайт, что при текущей цене на диски составит **несколько центов в год**.
>
> Возможное ускорение запросов вряд ли удастся обнаружить статистически, потому что сравнение четырех или четырнадцати байт&nbsp;&mdash; только часть работы,
> которую выполняет SQL сервер. Очень небольшая часть.
>
> Поэтому в этой статье мы не станем заниматься микрооптимизацией.

Содержимое таблицы, то есть лог посещений сервера, может быть таким:

|id |time                |ip            |method |uri                   |size  |status
|---|--------------------|--------------|-------|----------------------|------|------
|1  |2007-01-03 15:59:34 |192.168.10.68 |GET    |/images/name.gif      |1254  |404
|2  |2007-01-03 15:59:34 |192.168.10.68 |GET    |/images/combo.gif     |743   |200
|3  |2007-01-03 15:59:34 |192.168.10.68 |GET    |/images/harddrive.gif |947   |200
|4  |2007-01-03 16:00:33 |192.168.10.70 |POST   |/index.php	           |200   |6723
|5  |2007-01-03 16:01:52 |192.168.10.70 |GET    |/scripts/scripts.js   |11743 |200

Если наш сайт посещает десять тысяч человек в день, и каждый просматривает в среднем десять страниц, то за один квартал у нас наберётся приблизительно десять миллионов записей.
Подобный размер таблиц встречается нечасто, но именно на таких объёмах лучше всего рассматривать вопросы производительности.

Помимо количества записей на скорость выполнения запросов влияет также размер выборки. Одно дело, когда из большой таблицы нам нужны тридцать строк, и совсем другое, когда их три миллиона.
Однако, даже с определением объёма выборки могут возникнуть проблемы:

```sql
SELECT SUM(size) FROM HttpLog WHERE MONTH(time) = 1 AND YEAR(time) = 2007
```

Здесь СУБД просуммирует приблизительно треть нашей таблицы, но вернёт всего одно число. Для определённости мы будем считать, что объём выборки соответствует количеству обработанных записей,
то есть в данном случае приблизительно равен трём миллионам.

Под поиском мы будем понимать такую выборку, которая возвращает или одну запись или ни одной. Обычно на уровне SQL-запросов поиск не считается отдельной операцией,
и является частным случаем выборки. Однако с точки зрения реализации, поиск&nbsp;&mdash; это отдельная, и очень важная операция.

